[
  {
    "objectID": "data/kaya.html",
    "href": "data/kaya.html",
    "title": "kaya",
    "section": "",
    "text": "The Kaya Identity is an simple model for observing our planet from a highly macroscopic perscpective. 1.\nA mathematical identity is an equality relating one mathematicalto another statement in such a way that their values are identical. Wikepdia defines the identity as:\n\\[\n{\\displaystyle F=P\\cdot {\\frac {G}{P}}\\cdot {\\frac {E}{G}}\\cdot {\\frac {F}{E}}}\n\\] This identity becomes evident as P, E, G will cancel themselves out, leaving us simple with:\nBut, it becomes easier to read when the consituent parts are more explicit. Hence the following is identical:\n\\[\n{\\displaystyle CO_2=Population\\cdot {\\frac {GDP}{Population}}\\cdot {\\frac {EnergyUse}{GDP}}\\cdot {\\frac {CO_2}{EnergyUse}}}\n\\]\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n\nImagine yourself as an interstellar observer trying to understand a sudden spike in Eearth’s during what constitus, planetarily speaking, a microscopic timescale. Assuming that aliens have to report to their boss, their thinking would probably have to appeal to common sense and evolve along these lines:\n\n\n\nGreta\n\n\nThis is some more text to control the float\n\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n\n\\[\nCO_2 = P \\cdot\\frac{CO_2}{E} \\cdot\\frac{E}{GDP}\n\\cdot\\frac{GDP}{P}\n\\cdot\\frac{GDP}{Population}\n\\cdot P\n\\]\nThe first observation is that we live in a delicate balance with a burning ball of fire next to us. The surface of the earth is reflective, and sends the sun’s energy back into space. But with amount of Carbon in the air prevents\n\\[\nCO_2 = CO_2\n\\]\n\\[\nCO_2 = P\\cdot\\frac{CO_2}{E}\n\\] \\[\n\\text{ CO2 emissions = Carbon content of energy × Energy intensity of the economy × Production per person × Population}\n\\]"
  },
  {
    "objectID": "data/kaya.html#footnotes",
    "href": "data/kaya.html#footnotes",
    "title": "kaya",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is a re-working of Jean-Marc Jancovinci’s excellent article↩︎"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2\n\n\nDoes that answer makes sense"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "jakobsen.ca",
    "section": "",
    "text": "I am a programmer working mostly in R, Python, and Javascript. I write about data and methods that I find interesting and useful.\n“Much Ado about Nothing” is in part about deception and self-deception. Yet, we have a leg up on Shakepere, because we have easy access to data a plenty, especially in finance.\nPossibly the simplest and most useful tool is using R to quickly analyze the claims made about various financial products and services. The financial industry needs to justify its high fees, and thus is systemically wired to make mountains out of molehills, and to see patters that can be sold as “special sauce”.\n\n# Loads tidyquant, lubridate, xts, quantmod, TTR \nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidyquant)\n\nLoading required package: PerformanceAnalytics\nLoading required package: xts\nLoading required package: zoo\n\nAttaching package: 'zoo'\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\n######################### Warning from 'xts' package ##########################\n#                                                                             #\n# The dplyr lag() function breaks how base R's lag() function is supposed to  #\n# work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or       #\n# source() into this session won't work correctly.                            #\n#                                                                             #\n# Use stats::lag() to make sure you're not using dplyr::lag(), or you can add #\n# conflictRules('dplyr', exclude = 'lag') to your .Rprofile to stop           #\n# dplyr from breaking base R's lag() function.                                #\n#                                                                             #\n# Code in packages is not affected. It's protected by R's namespace mechanism #\n# Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning.  #\n#                                                                             #\n###############################################################################\n\nAttaching package: 'xts'\n\nThe following objects are masked from 'package:dplyr':\n\n    first, last\n\n\nAttaching package: 'PerformanceAnalytics'\n\nThe following object is masked from 'package:graphics':\n\n    legend\n\nLoading required package: quantmod\nLoading required package: TTR\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\ntq_index_options()\n\n[1] \"DOW\"       \"DOWGLOBAL\" \"SP400\"     \"SP500\"     \"SP600\"    \n\ngetSymbols(\"CARB.TO\",\n             from = \"2022-01-01\",\n             to = \"2022-12-31\")\n\n[1] \"CARB.TO\"\n\nstock &lt;- data.frame(CARB.TO$CARB.TO.Adjusted)\n\n\n\nstock &lt;- data.frame(stock,rownames(stock))\ncolnames(stock) &lt;- append('GOOG','date')\n\nfig &lt;- plot_ly(stock, type = 'scatter', mode = 'lines')%&gt;%\n  add_trace(x = ~date, y = ~GOOG, name = 'GOOG')%&gt;%\n  layout(showlegend = F)\noptions(warn = -1)\n\nfig"
  },
  {
    "objectID": "tennis.html",
    "href": "tennis.html",
    "title": "Ottawa Tennis Data",
    "section": "",
    "text": "Heat Predictions\nPlaying in the heat is tough, especially as players age. Do we need to adapt, or is there nothing to worry about? The City of Ottawa provides climate prediction data; this article tries to model some of the potential medium term effects.\n\n\nOttawa Data Sets\nNetCDF is a data format climate data, and has also been adopted in other fields, particularly in bioinformatics, and in other disciplines where large multidimensional arrays of data are generated. Unlike most data formats, NetCDF files contain metadata that describes what is contained in a file, such as the latitude and longitude layout of the grid, the names and units of variables in the data set, and “attributes” that describe things like missing value codes, or offsets and scale factors that may have been used to compress the data. NetCDF files are also machine-independent because can be transferred among servers and computers that are running different operating systems, without having to convert the files in some way. Originally developed for storing and distributing climate data, such as those generated by climate simulation or reanalysis models, the format and protocols can be used for other gridded data sets. NetCDF libraries are developed and maintained by Unidata http://www.unidata.ucar.edu/software/netcdf/ and easy-to-use applications for producing simple visualizations of NetCDF files exist, such as Panoply, http://www.giss.nasa.gov/tools/panoply/.\nThere are two versions of netCDF; netCDF3, which is widely used, but has some size and performance limitations, and netCDF4, which supports larger data sets and includes additional capabilities like file compression.\nR has the capability of reading and writing (and hence analyzing) netCDF files, using the ncdf and ncdf4 packages provided by David Pierce, and through other packages like raster, metR1, and RNetCDF. The ncdf4.helpers and easyNCDF packages provide some additional tools.\nLoad the ncdf4 package.\n# load the ncdf4 package\nlibrary(ncdf4)\nThe file is assumed to be a CF-compliant netCDF file, in which the three main spatiotemporal dimensions allear the the relative order of time (T-coordinate), height or depth (Z-coordinate), latitude (or Y-coordinate), and longitude (or X-coordinate). In this example, the file is a 3-D file with T, Y and X coordinates (month of the year, latitude, and longitude). First, set the values for some temporary variables. ncpath is the path to where the file was downloaded, ncname is the name of the netCDF file, while dname is the name of the variable that will be read in.\nhttps://ncc-ccn.gc.ca/our-plans/2023-2027-sustainable-development-strategy\nOpen the NetCDF file\n# set path and filename\nncpath &lt;- \"./data/nc_files/\"\nncname &lt;- \"cru10min30_tmp\"  \nncfname &lt;- paste(ncpath, ncname, \".nc\", sep=\"\")\ndname &lt;- \"tmp\"  # note: tmp means temperature (not temporary)\nOpen the NetCDF data set, and print some basic information. The print() function applied to the ncin object produces information similar to that produced by the command-line utility ncdump.\n# open a netCDF file\nncin &lt;- nc_open(ncfname)\nprint(ncin)"
  },
  {
    "objectID": "cues.html",
    "href": "cues.html",
    "title": "Cues",
    "section": "",
    "text": "Tennis Cues\n\nForehand\n\n\nBackhand\n\n\nServe"
  },
  {
    "objectID": "vision.html",
    "href": "vision.html",
    "title": "Vision & Reception",
    "section": "",
    "text": "Vision and Reception"
  },
  {
    "objectID": "heat.html",
    "href": "heat.html",
    "title": "Ottawa Tennis Data",
    "section": "",
    "text": "Heat Predictions\nPlaying in the heat is tough, especially as players age. Do we need to adapt, or is there nothing to worry about? The City of Ottawa provides climate prediction data; this article tries to model some of the potential medium term effects.\n\n\nOttawa Data Sets\nNetCDF is a data format climate data, and has also been adopted in other fields, particularly in bioinformatics, and in other disciplines where large multidimensional arrays of data are generated. Unlike most data formats, NetCDF files contain metadata that describes what is contained in a file, such as the latitude and longitude layout of the grid, the names and units of variables in the data set, and “attributes” that describe things like missing value codes, or offsets and scale factors that may have been used to compress the data. NetCDF files are also machine-independent because can be transferred among servers and computers that are running different operating systems, without having to convert the files in some way. Originally developed for storing and distributing climate data, such as those generated by climate simulation or reanalysis models, the format and protocols can be used for other gridded data sets. NetCDF libraries are developed and maintained by Unidata http://www.unidata.ucar.edu/software/netcdf/ and easy-to-use applications for producing simple visualizations of NetCDF files exist, such as Panoply, http://www.giss.nasa.gov/tools/panoply/.\nThere are two versions of netCDF; netCDF3, which is widely used, but has some size and performance limitations, and netCDF4, which supports larger data sets and includes additional capabilities like file compression.\nR has the capability of reading and writing (and hence analyzing) netCDF files, using the ncdf and ncdf4 packages provided by David Pierce, and through other packages like raster, metR1, and RNetCDF. The ncdf4.helpers and easyNCDF packages provide some additional tools.\nLoad the ncdf4 package.\n# load the ncdf4 package\nlibrary(ncdf4)\nThe file is assumed to be a CF-compliant netCDF file, in which the three main spatiotemporal dimensions allear the the relative order of time (T-coordinate), height or depth (Z-coordinate), latitude (or Y-coordinate), and longitude (or X-coordinate). In this example, the file is a 3-D file with T, Y and X coordinates (month of the year, latitude, and longitude). First, set the values for some temporary variables. ncpath is the path to where the file was downloaded, ncname is the name of the netCDF file, while dname is the name of the variable that will be read in.\nOpen the NetCDF file\n# set path and filename\nncpath &lt;- \"./data/nc_files/\"\nncname &lt;- \"cru10min30_tmp\"  \nncfname &lt;- paste(ncpath, ncname, \".nc\", sep=\"\")\ndname &lt;- \"tmp\"  # note: tmp means temperature (not temporary)\nOpen the NetCDF data set, and print some basic information. The print() function applied to the ncin object produces information similar to that produced by the command-line utility ncdump.\n# open a netCDF file\nncin &lt;- nc_open(ncfname)\nprint(ncin)"
  }
]